#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åŠ è½½å·¥å…·æ¨¡å—
æä¾›ç»Ÿä¸€çš„æ•°æ®åŠ è½½æ¥å£ï¼Œæ”¯æŒå¤šç§æ ¼å¼å’Œæ¥æº
"""

import os
import json
import logging
from typing import List, Tuple, Dict, Any
from config import Config

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataLoader:
    """ç»Ÿä¸€æ•°æ®åŠ è½½å™¨"""
    
    def __init__(self, base_dir: str = None):
        """
        åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        
        Args:
            base_dir: æ•°æ®åŸºç¡€ç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„
        """
        self.base_dir = base_dir or Config.KNOWLEDGE_BASE_PATH
        self.supported_extensions = {
            'text': ['.txt'],
            'json': ['.json'],
        }
        self.excluded_files = ['test_', 'crawl_stats.json']
        
    def _should_skip_file(self, filename: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æŸä¸ªæ–‡ä»¶"""
        return any(filename.startswith(prefix) for prefix in self.excluded_files)
    
    def _read_text_file(self, file_path: str) -> str:
        """è¯»å–æ–‡æœ¬æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read().strip()
        except Exception as e:
            logger.warning(f"è¯»å–æ–‡æœ¬æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return ""
    
    def _read_json_file(self, file_path: str) -> str:
        """è¯»å–JSONæ–‡ä»¶å¹¶è½¬æ¢ä¸ºæ–‡æœ¬"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return self._json_to_text(data)
        except Exception as e:
            logger.warning(f"è¯»å–JSONæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return ""
    
    def _json_to_text(self, data: Any) -> str:
        """å°†JSONæ•°æ®è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼"""
        if isinstance(data, dict):
            content_parts = []
            for key, value in data.items():
                if isinstance(value, (str, int, float)):
                    content_parts.append(f"{key}: {value}")
                elif isinstance(value, list):
                    # å¤„ç†åˆ—è¡¨æ•°æ®
                    if value and isinstance(value[0], dict):
                        # å¦‚æœæ˜¯å­—å…¸åˆ—è¡¨ï¼Œå±•å¼€æ¯ä¸ªå­—å…¸
                        for i, item in enumerate(value):
                            if isinstance(item, dict):
                                for sub_key, sub_value in item.items():
                                    content_parts.append(f"{key}_{i}_{sub_key}: {sub_value}")
                            else:
                                content_parts.append(f"{key}_{i}: {item}")
                    else:
                        # ç®€å•åˆ—è¡¨ç›´æ¥è¿æ¥
                        content_parts.append(f"{key}: {' '.join(str(item) for item in value)}")
                elif isinstance(value, dict):
                    # åµŒå¥—å­—å…¸
                    for sub_key, sub_value in value.items():
                        content_parts.append(f"{key}_{sub_key}: {sub_value}")
            return '\n'.join(content_parts)
        elif isinstance(data, list):
            return '\n'.join(str(item) for item in data)
        else:
            return str(data)
    
    def load_all_documents(self, show_progress: bool = True) -> Tuple[List[str], int]:
        """
        é€’å½’åŠ è½½æ‰€æœ‰æ”¯æŒçš„æ–‡æ¡£
        
        Args:
            show_progress: æ˜¯å¦æ˜¾ç¤ºåŠ è½½è¿›åº¦
            
        Returns:
            Tuple[List[str], int]: (æ–‡æ¡£åˆ—è¡¨, æ–‡ä»¶æ•°é‡)
        """
        if not os.path.exists(self.base_dir):
            logger.error(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.base_dir}")
            return [], 0
        
        documents = []
        file_count = 0
        
        if show_progress:
            print(f"ğŸ“‚ å¼€å§‹åŠ è½½æ•°æ®ç›®å½•: {os.path.abspath(self.base_dir)}")
        
        # é€’å½’éå†ç›®å½•
        for root, dirs, files in os.walk(self.base_dir):
            for file in files:
                # è·³è¿‡ä¸éœ€è¦çš„æ–‡ä»¶
                if self._should_skip_file(file):
                    continue
                
                file_path = os.path.join(root, file)
                content = ""
                
                # æ ¹æ®æ–‡ä»¶æ‰©å±•åå¤„ç†
                if file.endswith(tuple(self.supported_extensions['text'])):
                    content = self._read_text_file(file_path)
                elif file.endswith(tuple(self.supported_extensions['json'])):
                    content = self._read_json_file(file_path)
                
                # æ·»åŠ æœ‰æ•ˆå†…å®¹
                if content and content.strip():
                    documents.append(content)
                    file_count += 1
                    
                    if show_progress:
                        relative_path = os.path.relpath(file_path, self.base_dir)
                        print(f"âœ… åŠ è½½æ–‡ä»¶: {relative_path}")
        
        if show_progress:
            print(f"\nğŸ‰ æˆåŠŸåŠ è½½ {file_count} ä¸ªæ–‡ä»¶ï¼Œå…± {len(documents)} ä¸ªæ–‡æ¡£")
        
        return documents, file_count
    
    def load_by_category(self) -> Dict[str, List[str]]:
        """
        æŒ‰ç±»åˆ«åŠ è½½æ–‡æ¡£
        
        Returns:
            Dict[str, List[str]]: æŒ‰ç±»åˆ«åˆ†ç»„çš„æ–‡æ¡£
        """
        categories = {
            'attractions': [],
            'reviews': [], 
            'corpus': [],
            'numbered': [],
            'other': []
        }
        
        if not os.path.exists(self.base_dir):
            return categories
        
        for root, dirs, files in os.walk(self.base_dir):
            for file in files:
                if self._should_skip_file(file):
                    continue
                
                file_path = os.path.join(root, file)
                content = ""
                
                # è¯»å–å†…å®¹
                if file.endswith('.txt'):
                    content = self._read_text_file(file_path)
                elif file.endswith('.json'):
                    content = self._read_json_file(file_path)
                
                if not content:
                    continue
                
                # åˆ†ç±»
                relative_path = os.path.relpath(file_path, self.base_dir)
                if 'attractions' in relative_path:
                    categories['attractions'].append(content)
                elif 'reviews' in relative_path or 'review' in file.lower():
                    categories['reviews'].append(content)
                elif 'corpus' in relative_path:
                    categories['corpus'].append(content)
                elif file.replace('.txt', '').replace('.json', '').isdigit():
                    categories['numbered'].append(content)
                else:
                    categories['other'].append(content)
        
        return categories
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        if not os.path.exists(self.base_dir):
            return {"error": "æ•°æ®ç›®å½•ä¸å­˜åœ¨"}
        
        stats = {
            "total_files": 0,
            "total_documents": 0,
            "file_types": {},
            "categories": {},
            "total_size": 0
        }
        
        categories = self.load_by_category()
        documents, file_count = self.load_all_documents(show_progress=False)
        
        stats["total_files"] = file_count
        stats["total_documents"] = len(documents)
        stats["categories"] = {k: len(v) for k, v in categories.items()}
        
        # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
        for root, dirs, files in os.walk(self.base_dir):
            for file in files:
                if self._should_skip_file(file):
                    continue
                
                file_path = os.path.join(root, file)
                ext = os.path.splitext(file)[1].lower()
                
                if ext not in stats["file_types"]:
                    stats["file_types"][ext] = 0
                stats["file_types"][ext] += 1
                
                try:
                    stats["total_size"] += os.path.getsize(file_path)
                except:
                    pass
        
        # è½¬æ¢æ–‡ä»¶å¤§å°ä¸ºå¯è¯»æ ¼å¼
        size_mb = stats["total_size"] / (1024 * 1024)
        stats["total_size_mb"] = round(size_mb, 2)
        
        return stats

# å…¨å±€æ•°æ®åŠ è½½å™¨å®ä¾‹
default_loader = DataLoader()

# ä¾¿æ·å‡½æ•°
def load_all_travel_data(data_dir: str = None, show_progress: bool = True) -> Tuple[List[str], int]:
    """
    åŠ è½½æ‰€æœ‰æ—…æ¸¸æ•°æ®çš„ä¾¿æ·å‡½æ•°
    
    Args:
        data_dir: æ•°æ®ç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶è·¯å¾„
        show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
        
    Returns:
        Tuple[List[str], int]: (æ–‡æ¡£åˆ—è¡¨, æ–‡ä»¶æ•°é‡)
    """
    loader = DataLoader(data_dir)
    return loader.load_all_documents(show_progress)

def get_data_statistics(data_dir: str = None) -> Dict[str, Any]:
    """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯çš„ä¾¿æ·å‡½æ•°"""
    loader = DataLoader(data_dir)
    return loader.get_statistics()

# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•æ•°æ®åŠ è½½å™¨...")
    
    # æµ‹è¯•åŠ è½½æ‰€æœ‰æ•°æ®
    docs, count = load_all_travel_data()
    print(f"âœ… åŠ è½½å®Œæˆ: {count} ä¸ªæ–‡ä»¶, {len(docs)} ä¸ªæ–‡æ¡£")
    
    # æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯
    stats = get_data_statistics()
    print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
